集群搭建在http://172.18.111.3:19999/home 每个worker 2G

  sc.hadoopConfiguration.set("fs.alluxio.impl", "alluxio.hadoop.FileSystem")

举个栗子：
spark.sql("select * from gus.t1").write.save("alluxio://172.18.111.3:19998/t1")
这里默认进入alluxio发现会得到一个压缩的parquet，太好了，parquet由于有sechma，转表太easy

进程A：
spark.read.parquet("alluxio://172.18.111.3:19998/t1").createOrReplaceTempView("t1")

进程B：
spark.read.parquet("alluxio://172.18.111.3:19998/t1").createOrReplaceTempView("t1")

以上两个进程都是从内存中读取到的parquet而非磁盘

这样跨进程共享内存中同一份数据spark办不到由alluxio中转方式完成

官方介绍，对于超大规模数据读取alluxios一定是线性的。数据量很小的情况还是spark略有优势
alluxio不仅仅是数据读取层面的加速它还弥补了spark一些落盘的劣势，在计算方面也有一些加速